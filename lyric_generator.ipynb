{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lyrics text file\n",
    "with open('./data/lyrics.txt', encoding='utf-8') as f:\n",
    "    raw_lyrics = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines: 1792\n",
      "Total number of unique words (roughly): 1964\n",
      "Average number of words in a line: 3.763392857142857\n",
      "The least number of words in a line: 0\n",
      "The most number of words in a line: 13\n",
      "\n",
      "Lyric preview:\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "\n",
      "끌리네 그 누구와도 다르게\n",
      "변하고 싶어 나\n",
      "너를 바라보면서 yeah\n",
      "너를 알아가면서 yeah\n",
      "\n",
      "상상이 내 감정을 더 움직여\n",
      "열두 가지 색색깔의 무지개\n",
      "나는 과연 어떤 색일까\n",
      "우리 더 빛나게 해볼까\n",
      "\n",
      "천천히 하나 둘 그리는 하얀 종이 위에\n"
     ]
    }
   ],
   "source": [
    "# data statistics\n",
    "lyrics_per_line = raw_lyrics.split('\\n')\n",
    "word_count_line = [len(line.split()) for line in lyrics_per_line]\n",
    "\n",
    "print('Total number of lines:', len(raw_lyrics.split('\\n')))\n",
    "print('Total number of unique words (roughly):', len({word: None for word in raw_lyrics.split()}))\n",
    "print('Average number of words in a line:', np.average(word_count_line))\n",
    "print('The least number of words in a line:', np.min(word_count_line))\n",
    "print('The most number of words in a line:', np.max(word_count_line))\n",
    "print()\n",
    "\n",
    "view_range = 20\n",
    "print('Lyric preview:')\n",
    "print('\\n'.join(raw_lyrics.split('\\n')[:view_range]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# check which punctuations do the lyrics have\n",
    "def check_punctuations(lyrics):\n",
    "    flag = False\n",
    "    punct_list = []\n",
    "    for p in punctuation:\n",
    "        if raw_lyrics.find(p) != -1:\n",
    "            flag = True\n",
    "            punct_list.append(p)\n",
    "\n",
    "    return (flag, punct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, ['!', \"'\", '(', ')', ',', '-', '/', '?'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_punctuations(raw_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(lyrics):\n",
    "    word_count = Counter(lyrics)\n",
    "    sorted_word_count = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(sorted_word_count)}\n",
    "    int_to_vocab = {idx: word for word, idx in vocab_to_int.items()}\n",
    "    \n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "def create_token_lookup():\n",
    "    punctuations = ['!', \"'\", '(', ')', ',', '-', '/', '?', '\\n']\n",
    "    tokens = ['<EXCLAMATION_MARK>', '<SINGLE_QUOTATION_MARK>', '<LEFT_ROUND_BRACKET>', '<RIGHT_ROUND_BRACKET>',\n",
    "              '<COMMA>', '<HYPHEN>', '<SLASH>', '<QUESTION_MARK>', '<NEW_LINE>']\n",
    "    \n",
    "    punct_token = {}\n",
    "    for p in range(len(punctuations)):\n",
    "        punct_token[punctuations[p]] = tokens[p]\n",
    "        \n",
    "    return punct_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "token_lookup = create_token_lookup()\n",
    "for symbol, token in token_lookup.items():\n",
    "    raw_lyrics = raw_lyrics.replace(symbol, ' {} '.format(token))\n",
    "\n",
    "tokenized_lyrics = raw_lyrics.lower()\n",
    "tokenized_lyrics = tokenized_lyrics.split()\n",
    "    \n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(tokenized_lyrics)\n",
    "encoded_lyrics = [vocab_to_int[word] for word in tokenized_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available! Training on: GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch\n",
    "\n",
    "gpu_availability = torch.cuda.is_available()\n",
    "\n",
    "if gpu_availability:\n",
    "    print('GPU Available! Training on:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU found! Training on CPU...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_lyric(lyrics, sequence_length, batch_size):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for w in range(len(lyrics)):\n",
    "        if w+sequence_length < len(lyrics):\n",
    "            features.append(lyrics[w:w+sequence_length])\n",
    "            labels.append(lyrics[w+sequence_length])\n",
    "    \n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    dataset = TensorDataset(torch.from_numpy(features), torch.from_numpy(labels))\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1186,    0,  684,  218,  165],\n",
      "        [ 115,  178,  296,    0,   92],\n",
      "        [   0,    0,   10,   96,   10],\n",
      "        [ 368, 1401, 1402, 1403,  215],\n",
      "        [1265,  716,   43,    0, 1266],\n",
      "        [  82,   23,    7,    0,   45],\n",
      "        [  80,    0,  154,  102,  112],\n",
      "        [ 193,  475,  136,    0,  231],\n",
      "        [1207, 1208,    2,   13,    3],\n",
      "        [   2,  331,   19,    3,    0]], dtype=torch.int32)\n",
      "tensor([313, 560,  10, 108,  45, 335,   0,  55,   0,  20], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_loader = batch_lyric(encoded_lyrics, sequence_length=5, batch_size=10)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "f, l = train_iter.next()\n",
    "print(f)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
