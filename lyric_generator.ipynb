{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZ*ONE Lyric Generator\n",
    "\n",
    "Welcome to the IZ*ONE Lyric Generator notebook! I will guide you through this notebook on how to preprocess our data and train them with an LSTM network. First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can read our .txt file from the /data directory using the open() function from python. **Don't forget to specify the encoding to 'utf-8' when you are trying to read non-English characters in your lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lyrics text file\n",
    "with open('./data/lyrics.txt', encoding='utf-8') as f:\n",
    "    raw_lyrics = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines: 1792\n",
      "Total number of unique words (roughly): 1964\n",
      "Average number of words in a line: 3.763392857142857\n",
      "The least number of words in a line: 0\n",
      "The most number of words in a line: 13\n",
      "\n",
      "Lyric preview:\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "\n",
      "끌리네 그 누구와도 다르게\n",
      "변하고 싶어 나\n",
      "너를 바라보면서 yeah\n",
      "너를 알아가면서 yeah\n",
      "\n",
      "상상이 내 감정을 더 움직여\n",
      "열두 가지 색색깔의 무지개\n",
      "나는 과연 어떤 색일까\n",
      "우리 더 빛나게 해볼까\n",
      "\n",
      "천천히 하나 둘 그리는 하얀 종이 위에\n"
     ]
    }
   ],
   "source": [
    "# data statistics\n",
    "lyrics_per_line = raw_lyrics.split('\\n')\n",
    "word_count_line = [len(line.split()) for line in lyrics_per_line]\n",
    "\n",
    "print('Total number of lines:', len(raw_lyrics.split('\\n')))\n",
    "print('Total number of unique words (roughly):', len({word: None for word in raw_lyrics.split()}))\n",
    "print('Average number of words in a line:', np.average(word_count_line))\n",
    "print('The least number of words in a line:', np.min(word_count_line))\n",
    "print('The most number of words in a line:', np.max(word_count_line))\n",
    "print()\n",
    "\n",
    "view_range = 20\n",
    "print('Lyric preview:')\n",
    "print('\\n'.join(raw_lyrics.split('\\n')[:view_range]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# check which punctuations do the lyrics have\n",
    "def check_punctuations(lyrics):\n",
    "    flag = False\n",
    "    punct_list = []\n",
    "    for p in punctuation:\n",
    "        if raw_lyrics.find(p) != -1:\n",
    "            flag = True\n",
    "            punct_list.append(p)\n",
    "\n",
    "    return (flag, punct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, ['!', \"'\", '(', ')', ',', '-', '/', '?'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_punctuations(raw_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(lyrics):\n",
    "    word_count = Counter(lyrics)\n",
    "    sorted_word_count = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(sorted_word_count)}\n",
    "    int_to_vocab = {idx: word for word, idx in vocab_to_int.items()}\n",
    "    \n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "def create_token_lookup():\n",
    "    punctuations = ['!', \"'\", '(', ')', ',', '-', '/', '?', '\\n']\n",
    "    tokens = ['<EXCLAMATION_MARK>', '<SINGLE_QUOTATION_MARK>', '<LEFT_ROUND_BRACKET>', '<RIGHT_ROUND_BRACKET>',\n",
    "              '<COMMA>', '<HYPHEN>', '<SLASH>', '<QUESTION_MARK>', '<NEW_LINE>']\n",
    "    \n",
    "    punct_token = {}\n",
    "    for p in range(len(punctuations)):\n",
    "        punct_token[punctuations[p]] = tokens[p]\n",
    "        \n",
    "    return punct_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "PADDING = {'PADDING': '<PAD>'}\n",
    "\n",
    "token_lookup = create_token_lookup()\n",
    "for symbol, token in token_lookup.items():\n",
    "    raw_lyrics = raw_lyrics.replace(symbol, ' {} '.format(token))\n",
    "\n",
    "tokenized_lyrics = raw_lyrics.lower()\n",
    "tokenized_lyrics = tokenized_lyrics.split()\n",
    "    \n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(tokenized_lyrics + list(PADDING.values()))\n",
    "encoded_lyrics = [vocab_to_int[word] for word in tokenized_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['<new_line>', '<comma>', '<left_round_bracket>', '<right_round_bracket>', 'oh', '<single_quotation_mark>', 'i', 'you', 'me', 'm', 'da', 'ooh', '<hyphen>', 'yeah', '더', '이', 'la', '내꺼', 'my', '<exclamation_mark>', '내', 'so', 'hey', 'like', 'it', '나를', 'eh', 'swan', '아름다운', 'up', '꼭', '우리', '수', 'curious', 'eyes', '거야', '너의', '난', '지금', '내꺼야', 'don', 't', '그', '걸', 'hush', '너와', '모든', '날', '색', '나', '네', '순간', 'ah', 'rose', '꿈을', '두', '저', '내가', '함께', '<question_mark>', 'be', '나의', 'with', 'baby', 'crazy', '없는', 'pretty', '느낌', '넌', '다운', '있어', '다', 'on', 'o', 'love', 'your', 'wake', '눈', 'vie', 'en', '있게', 're', 'really', 'know', 'have', '속에', 'wanna', 'pick', 'color', '싶어', 'whoa', 'all', '이제', '올라가', '너를', 'now', 'ra', '우리만의', '좋아', 'go', 'make', '눈빛', '잘', '닿을', '한', '좀', 'a', 'right', 'dream', 'ever', 'seen', '빛이', '부탁해', '손을', 'sweet', '손', '기억해', '빠져들어', '어떤', '자꾸', 'and', '맘', 'na', '해', '눈을', 'promise', '오늘부터', '내게', '빛나는', '기분', '바로', '봐', '있는', '언제나', 'we', '마', '줘', '가득', '꿔', 'for', '때까지', 'rococo', 'this', '늘', '이런', '모르게', '하늘에', 'look', '우린', '맘을', '반짝이는', '우아하게', '모두', '될', '앞으로', '돼', '매일', '때', 'about', '우연이', 'always', '나도', '담아', '만든', '시간은', '원하는', '가득해', '게', '널', '여기', '소중한', '속', '우리의', '않을', '순간이', '위한', '바라봐', '너', '잡고서', 'fallin', 'fiesta', '끝까지', 'open', '봐요', '천천히', '할', '좋은', '안에', 'do', '이건', '시간', 'll', '보여줄', '놓지', 'at', 'just', '춤을', '춰', 'cat', '계속', '화려한', '아냐', 'no', 'mama', 'sweetie', 'anything', '위에', '이끌려', '예쁜', '멋진', '너무', 'bae', 'can', 'feel', '앞에', '같은', '마치', 'aha', '네가', '것', '알고', '어서', '아무도', '나다운', '꿈이', '마주', '또', '곁에', '지나', '작은', '그날', '따스한', '필요', '깊이', '점점', '같아', '계절', '깊게', '항상', 'spaceship은하수', '지나서', '노랫소리', '피슝', '날아가', '온기', '아래', '아니야', 'daydream', '자', '싶은', 'round', 'ro', 'better', '기대', '나는', '곁에서', '그리고', '서로', '온통', '어지러워', '따라', 'catch', '번져', 'red', '서', '빛날', '같이', '시선', '새로운', '마음을', '끝이', '나에게', 'friends', '걸음', 'shining', '멈추지', 'want', '말해줄래', '닿길', '바래', '약속해', 'hi', '바람', '꿈꾸던', '노래', '그대', '만난', '본', '않을게', '창밖의', '지나간', '나와', '건', '무대', '가', 'one', '따라와', '눈이', 'uh', 'surprised', 'lot', '선명한', '벚꽃', '꿈에', '이룰', '그리는', 'will', '싶어요', 'show', '물들여', '다른', '우리가', '색이', '대로', '채', '온', '별이', '쏟아져', '몰라', '맘에', 'is', '전부', '줄게', '채우고', '내일', '걸어', '혼자', '않아', '꾸는', '것만', 'uhh', 'woo', 'lalala', 'lalalla', '시간을', '함께라서', '안아줘', '잡아', 'cause', 'star', '마음이', '너에게', '보여줄게', '시간이', 'only', '물든', '기적을', '이젠', '처음', 'forever', '향해', '이대로가', '따윈', '없잖아', '꿈꿀래', '오직', 'yourself', 'myself', '와', '가까이', '불꽃처럼', 'eye', '놀러', 's', '부셔', 'ayayayayaya', 'gonna', '둘이', '적', 'dreams', '변하지', '손잡아', '순간의', '우리를', '말하지', '않아도', '영원히', '달콤해', '어둠', '있잖아', '잊지', '못하게', '세계', 'gotta', 'some', '준비돼있어', 'yolo', '하나', '둘', '하얀', '색은', '비밀이', '열려', 'i’ll', 'colors', '하늘', '세상', '나만의', '별빛처럼', '흔들어', '나만', '담은', 'come', '펼쳐지는', '상상했던', '하루', '종일', '톡', '쏘는', 'jerry', '놀랍지', '근데', '첫사랑인', '말로', '담지', '못할', '향기처럼', '향한', 'stop', '심장이', '어쩜', '빨갛게', '어느새', '새롭게', 'ruby', '춤추게', '잊지마', 'it’s', '말', '손에', '오늘이', '올지', '몰라도', '모레도', '잠시', '비춘', '햇살', '위해', '기억해줘', 'dear', '동안', '언제라도', '다시', '따뜻한', '기다릴게', '맘이', '없어', '너로', '할래', '나야', 'story', '반짝반짝', '커지는', '빛', '찬란하게', '사랑', '너만', '바라볼게', '짜릿해', '곳에', '닿는', '향기', 'way', '이렇게', '위로', 'goodness', 'yes', '숨결이', '놀라게', '손길이', '섞인', '만들어', 'to', '이미', 'day', '말아', '환하게', '수놓은', '우릴', '잡고', '하늘을', '흐르는', '바람이', '내게만', '길을', '가는', '눈빛에', 'tonight', 'night', '눈부시게', '오랜', '기다림을', '좋을', '꿈들이', '하나만', '지금이라고', '태양을', '꾹', '삼킨', '영원토록', '뜨겁게', '지지', '축제', '번쯤은', '축제니까', '자신', '새로워진', '지켜봐', '운명처럼', '망설이지', '말고', '내게로', 'own', 'pilot', '왜', '눈앞에', '우리는', '목소리', '슝슝', 'spaceship', '별', '밤', '꿈', '운명인', '나눈', '약속처럼', '눈부시던', '설렘', '조명이', '혼자라면', '떨리는', '돼줄게', '느껴', '기다려온', '찬란한', '뜬', '언젠가', '다신', '두려워하지는', '않죠', '걸어갈게요', '만큼', '떠', '다가와서', '담아줘', 'new', '비밀', '위해서', '이대로', 'sweety', '안아주고', '숨길', '감출', '그대로', '그것만으로', '찾아와', 'step을', '밟아', '사뿐하게', '회전목마같이', '지루한', '관념들을', '벗어나', '벅찬', '감정을', '움직여', '가지', '무지개', '빛나게', '종이', '빨주노초파남보', '어울리는', '뭐', 'magic', '것처럼', '나로', '벌써', 'into', '색칠하고', 'that', '보게', '투명한', '유리컵', '너무나', '막', '내려', '사로잡아', '넘쳐', '싱그러운', '꽃잎', '환상의', '뜨거운', 'knock', '느낌은', '보다', '느끼는', '끌리면', 'don’t', 'blue', '깊어진', '붉어진', '타오르게', '완벽해진', '사탕보다', '칠해봐', '바람에', '보이는', '넓은', '준', 'you’re', '용기로', '반복되는', '매일이', '않게', '서로를', '세상이', '눈동자도', '깊은', '멈춰', '때로는', '어디든지', '사라질', '같아도', '감고', '귀를', '기울여', '이제야', '어디에', '있는지', '되어', '절대', 'dreaming', '터질', 'hold', '맘속에', '믿는다면', '잡아줄래', '니', '맘속의', '주인공은', 'superstar', '오늘밤', '시작이야', 'tell', '살짝', '빠졌어', '너는', '약속', '부는', '파랗게', '활짝', '바라보는', '시선이', '우리들만의', '신비로운', '따라서', '발길을', '멈춘', 'the', 'shines', 'twinkle', '따뜻해', '채워', '너란', '색깔들로', '말할게', '닿은', '물들어', '오래전부터', '있던', '떠올라', 'remember', '추웠나', '얼어붙은', '겨울', '새싹이', '자라나', '잡아줘', '꿈꿀', '유난히', '포근한', '속을', '된', 'more', '그저', '보여', '잃어', '미로', '가슴', 'chasing', '빨라져', '소리', '보여줘', '날아올라', '눈에', '새겨지는', '듯한', '줄', '눈빛을', 'sunshine', '몇', '왔어', '말해', '축제를', '색색의', '꽃을', '피우고', '꽃가루가', '흩날리면', '축제는', '절정인', '끝나지', 'climax', '아름답고', '눈부셔', '이거', '왔던', '길', '비춰', '하나씩', '그리', 'ayayayayayaya', '빠져', 'falling', '아득해져', '주인공이', '모두가', '수가', '두근대는', 'spotlight', 'flower', 'how', '너무너무', '몰래', '우주선', '듯', '눈치만', '보고', '두근두근해', '아리송한', '표정이', '붕붕붕붕', '신나', '아무', '말이나', '아차차', '떠본', '이래', '어떡해', '완벽한', '기다렸던', '라라라', '느껴져', 'hug', '기다려', '있을', '펼쳐진', '세상은', '넓고', '달려갈', '하나의', 'let', '이야기', '새하얀', '설레임', '꽃향기', '보며', '선', '계절처럼', '꿈꿔온', '때문일', 'listen', '그리던', '깨지', '빠져만', '서툴던', '숨', '쉬게', '조각들', '현실이', '밤도', '지나가겠죠', '끝없는', '어둠이', '밀려와도', '끝자락', '바라왔던', '없을', '사랑은', '시작됐어', 'fresh', '특별해', '순간들이', '다가올', '그때까지', '마법에', '깨어나', '여긴', '누구보다', '홀연히', '거죠', 'feeling', '그곳에', '그대는', '모르겠죠', '담아서', 'around', '돌', '함께해', '있어줘', 'merry', '둘만의', '세상엔', '물음표만', 'alright', '정답을', '찾아', '말할래', '공간', '비출', '세계로의', '초대', '빛나고', '남게', '될걸', 'style', '꺼지지', '않는', '설명', '못해', '들뜬', '기억', '잊어요', '와줘', '웃어', '살며시', '전하고', '옆에서', '지켜줄게', '하나만을', '끌리네', '누구와도', '다르게', '변하고', '바라보면서', '알아가면서', '상상이', '열두', '색색깔의', '과연', '색일까', '해볼까', '색다른', '주문을', '걸었지', '입술', 'shop', '인', '첫', '번째', '맘대로', '미술', '붕', '뜨는', '괜히', '두근거려', 'black', 'white', '칠해놓은', '색깔', '모이니까', '그림이', '돼버리잖아', '짜릿하게', '번져가니까', '손끝부터', '발끝까지', '반짝이니까', '짜릿해져', 'everyday', 'let’s', 'watch', '어머나', '갑자기', '앞이', '아찔해', '빨라진', '심장에', '놀란', '얼어버린', '걸요', '방심한', '숱한', '불꽃놀이', 'mamma', 'mia', '네온', '사인처럼', '머릿속이', '야단이야', '막연하게', '한계치를', '넘겨', '아니', '흘러', '다니는', '전류', '짜릿한', 'soda', '뛰어든', '같애', '수없이', '참아봐도', '아직까진', '여전해', '놀라대', '곤란해', 'fallin’', '물감', '색깔로', 'fantasy야', '격하게', 'roller', 'coaster', '앗', 'toaster', '깜짝이야', '갖고', '그래', '학교에서', '거리에서', '멋대로', '그려대는', '멎게', '펼치는', '날개', '세상에서', '왔을지', '데려가', '빨간', '장미처럼', '반짝임처럼', '상상해봐', '기대해도', '왠지', '가까이서', '봐도', '누구보다도', '물들일게', '달콤함처럼', '만들어봐', '감았던', '떠봐', '달라져', '모르는', '세상을', '꿈이라도', '언제든', '깨어날', '불러', '장밋빛에', '물들게', '새빨가아아안', '나아아아', '특별하게', '만약', '말로만', '전한다면', '흩어질', '같아서', '안녕이란', '마음은', '좀처럼', '쉽지', '않아서', '그래서', '안', '문', '데려다', 'angel', '마음속에', '끄적인', '보잘것없는', '낙서는', '봐주면', '한걸음', '뒤따라', '뒷모습이', '외롭지', '해줘서', '넘어지고', '걷다', '숨이', '차올라도', '행복이', '된다면', '슬플', '때라면', '보고서', '위로해주고', '안아주고서', '지켜줘', '커져가', '놀라', '커져', '숲', '헤매다', '뒤돌아', '봤어', '멀어지는', '길이', '두려워', '우연히', '따뜻했던', '너였어', '날부터', '꾼', '힘들고', '지친다', '해도', '돌아가지', '생각만으로', '함께했던', '날들', '발끝을', '숲을', '언덕', '알겠어', '작게만', '보여서', '멀어질까', '불안하지만', '지금껏', '걸어온', '걸겠어', '외롭고', '주저앉아도', '결국에는', '포기하지', '않았어', '흘러내린', '빗방울이', '비춰줄', '흘린', '눈물은', '아마', '멈출', '수는', '없겠지만', '고마웠어', '지친', '위로해준', '햇살에', '여기까지', '올', '있었어', '스쳐가고', '잃어버렸던', '날처럼', '마지막', '인사를', '하지만', '만나', '꿈속에', '하는', '멈추지는', '행복했어', '꿈꿔왔던', '듯해', '더는', '숨길수가', '봐봐', '느껴지니', '가득한', '찌릿찌릿', '저장', '지나가면', '놓쳐', '버릴지', '마주치면', '이제는', '받은', '사랑이', '채워주는', '뻗은', 'give', '도화지를', '햇빛', '그림같이', '두근거렸어', '너도', '함께하면', '반짝일', '테니까', '곁으로', '다가와', '않겠단', '손끝에', '투명해', '부드러워', '섞이는', '향기로', '이름', '숨결', '기다려왔죠', '추운', '겨울이', '봄이', '오는', '소리에', '잠들어', '뛰어', '그때가', '많이', '오늘도', '차가운', '외투가', '되어준', '올려다본', '별들', '용기', '말은', '밤하늘의', '별은', '되고', '새들의', '노래가', '시작되고', '멜로디에', '맞춰', 'us', '좋았던', '추억', '하나부터', '열까지', '말야', '내일도', 'think', '그날의', '떠올려', '어제보다', '뼘', '자란', '잡을게', '함께라면', '아늑한', '소파', '쏟아지는', '아침', '햇살이', '이불', '뒹구르게', '잔잔히', '느긋한', '속에서', '여유로운', '일상', '번', '돌아오지', '신경', '쓰지', '너에게만', '흔들리는', '커튼', '속삭이듯', '간지럽혀', '어디로든', '살랑이는', '부르는', '걸을래', '볼래', '아무런', '걱정하지', '충분해', '그거면', '조심스럽게', '열린', '문틈', '사이로', '비추는', '믿어봐', '모습도', '시선보단', '소중해', '무엇보다', '중요한', '너니까', '황홀히', '이어진', '색의', '빠져들길', '시간도', '잊어', '가길', 'movie', 'wait', '거친', '몰아치는', '모습과', '강렬해져', 'action', '뛰게', '하잖아', '휘날린', '향기를', '심장', '녹아', '담긴', 'talking', '비밀스러운', '암호', '같지', 'by', '이어져', '별자리', 'of', '홀린', 'moving', '어때', '그냥', '따라오면', '원해도', '거침없이', '빠져들면', '그래도', '열기를', 'fantasy', '이끈', '넘치는', '비춰와', '말도', '피어나는', 'hope', '바라봐줘', '번이라도', '마주칠', '품에', '안아', '놓치지', '눈으로', '전해지는', '때가', '끝내', '움츠렸던', '일으켜', '기지개를', '켜', '눈빛은', '어느샌가', '짙어져', '됐어', '아침에게', '아득했던', '멀지가', '열어볼', '때란', '거', '그것', '역시', '정해', '이제부터가', '기대해봐도', '뛰어올라', '소리쳐봐', '신기루가', '상상해', '특별해지는', '별들에게', '내일이', '일들이', '겁나지', '이어갈', '감싸', '안은', '낯선', '감아', '멈춰있던', '깨워', '안의', '안아주면', '여러', '때면', '그려왔던', '진짜', '모습', '비춰줘', '걷는', '불빛', '뭐가', '성급해', 'runway', '조금', '당당한', 'walking', '집중되는', '눈길', '발짝', '걸어가', '지금부터', '테니', '감탄해봐', 'melody', '들리게', '속삭여봐', '귓가에', '들린', '종소리', 'down', '뭔', '말이', '필요해', '떠들썩한', '공기', '틀림없이', '축제인', '곳이면', '무대야', '주목하게', 'focus', '높아지는', 'volume이', '마음속', '끌림을', '설명할', '증거', '어쩔', '없을걸', 'aya', '와봐', '오로지', '숨죽여', '짜여진', '시나리오', '그대론', '재미없어', '더욱더', '새로워져', '내일의', '기대해봐', 'wow', 'choco', '잠깐', '가도', '돼요', '궁금한데', '올라탄', '빨라', '꽉', '몸에', '말듯', '타고났어', '로맨틱', '넘어진', '놀라버린', '어머', '얼굴', '아껴둔', '옷', '입고서', '반해버린', '표정', '싱글싱글', '레몬처럼', 'item', '파티', '음', '너랑', '것이', '두리번두리번거리던', '어리던', '꼬마는', '이렇게나', '커서', '노래를', '부르며', '사랑을', '찾아요', '그려요', '드넓은', '세상에', '찍은', '발', '도장', '신호', '티', '빛나', '선물', 'awoo', 'romantic', 'mm', 'mwah', '문을', '열어봐', '밝게', '채워져', '쓰담아', '주는걸', '24', '<slash>', '7', '어릴', '일기장에', '쓴', '보석', '넓게', '빠르게', '오를', 'here', '슝', '하고', '찾았다', '꿨는데', 'being', 'shooting', '알게', '별자리를', '찾아낼', '멀지는', 'our', '하나둘', '시작된', '마법', '기적이', '인한', '전속력으로', '예뻤던', '그날을', '계절에', '만났던', '꽃잎도', '여전히', '닮은', '날들이', '행복해서', '순간을', '잊을', '눈빛도', '이토록', '변함없는', '품었던', '소원이', '흩날리던', '눈빛만으로', '알', '있었던', '간절했던', '운명', '같았던', '잡은', '하늘의', '이유는', '밤이', '까맣기', '어두운', '조용히', '흐른', '눈물이', '됐기', '켜지고', '들려', '맘속', '자라던', '피어', '순간만을', '기다려왔어', '주는', '보면', '목소리로', '눈빛들', '꿈이라면', '않고', '노래할게', '언제까지나', '영원해', '우리라는', '이름은', '감은', '위', '말없이', '쏟아진', '황홀함', '아마도', '여기는', '꿈인', '걸까', '빛과', '오묘한', '향기가', '가득히', '펼쳐질', '서랍', '깊숙이', '넣어둔', '듯이', '이루어질', '더없이', '향해서', '발로', '걸어볼까', '온몸에', '녹아든', '맛은', '참', '뜬대도', '머물러줄', '걸음마다', '아름다워', '꿈속', '어딘가', '속으로', '짙게', '깔려진', '안개에', '멀어지고', '뻗어', '바라보지만', '돌고', '돌죠', '헤매일까요', '길었던', '밤을', '비췄던', '밤하늘', '별빛을', '밝혀주네요', '비추면', '걸음씩', '나아갈게요', '먼', '길이라도', '맞잡은', '볼', '그때', '미소', '짓겠죠', '우리이기에', '밝은', '빛으로', '뭐야', '감아도', '상상들이', '되는', 'amazing', '빨라지는', '심장을', '표현할', 'awake', '주저하는', '달라질', '우리들', '손길', '차가움', '씻어내', '신선해', '설레는', '떨림', '가까워진', '사이', '떨어지기', '싫은', '커져가는', '거부할', '강하게', '이상', '번을', '떠도', '너야', '현실보다', '생생한', '들어볼래', '동화', '나올', '법한', '얘기', '담아둘래', '가득해진', '문이', '열리게', '들어가', '손끝에서', '시작되는', 'fairy', 'tale', '비웃어도', '꿀래', '곳으로', '갈래', 'afraid', '슬픈', '엔딩은', 'anyway', '영원할', '거라고', '믿어', '주인공처럼', 'fly', 'away', 'paradise', '상상으로', '채워가', '영원하기를', '바라', '맞추며', '그려봐', '예쁘게', 'drawing', '웃음', '푹', '조금씩', 'diving', '꿈처럼', '피어난', '숲처럼', '바라보면', '볼수록', '빠져들게', '하는데', 'ya', '대체', '어디서', '나타나', '건지', '궁금해', '미쳐', '빛이나', '싱그런', '멜로디', '메모리', '다가가면', '갈수록', '빠져들고', '마는데', '힘이', '들면', '혼자가', '잠들었어', '비밀로', '했었던', '창문을', '열어보면', '봄바람이', '꿈이여', '아직', '모습을', '보여주었던', '분홍빛으로', '아무에게도', '들키지', '보여주고', '꿈에서', '보기로', '조각한', '춤추는', 'true', '꿈은', '돌아', '어제와', '오늘', '공기마저', 'fingertips', 'two', 'three', 'four', '아직은', '낯설지만', '세계로', 'almost', 'there', '끌림은', '없고', '섣부른', '판단은', 'got', 'loco', '원해', '남고', '전율이', '퍼져', '빛을', '우주를', '그려', '별들이', '사뿐히', '내디뎌', '멈춰진', '여기에', '있을게', '함께할', '알잖아', 'move', '맡겨', '타오른', 'sing', '어제부터', '지금까지', '한숨도', '못', '잤어', '그때의', '기억들이', '떠올라서', '아프게만', '전하지', '못한', '마음으로', '후회만', '해요', '채워갈', '순', '없지만', 'waiting', '있는다', '기다리다가', '생각에', '잠겨', '결국엔', '봄바람도', '찾아왔죠', '아프게', '지켜줄게요', '예쁘던', '기억들로', '꽃이', '필', '설레던', '만남처럼', '아껴왔던', '말들을', '전할', '기억할게', '<PAD>'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available! Training on: GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch\n",
    "\n",
    "gpu_availability = torch.cuda.is_available()\n",
    "\n",
    "if gpu_availability:\n",
    "    print('GPU Available! Training on:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU found! Training on CPU...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_lyric(lyrics, sequence_length, batch_size):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for w in range(len(lyrics)):\n",
    "        if w+sequence_length < len(lyrics):\n",
    "            features.append(lyrics[w:w+sequence_length])\n",
    "            labels.append(lyrics[w+sequence_length])\n",
    "    \n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    dataset = TensorDataset(torch.from_numpy(features), torch.from_numpy(labels))\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   6,    5,    9,   33,  158],\n",
      "        [1412,  106, 1413,  339,    0],\n",
      "        [   7,  109,  110,  205,   59],\n",
      "        [ 135,   40,    5,   41,  418],\n",
      "        [ 100,   24,  263,    2,   26],\n",
      "        [  54,  350,  435,   50,  486],\n",
      "        [   6,    5,    9,   21,   33],\n",
      "        [   0,   94,  175,  196,  197],\n",
      "        [  23,   27,    1,   27,    1],\n",
      "        [   5,    9,   21,   33,    2]], dtype=torch.int32)\n",
      "tensor([   7,  507,    0,   24,   26, 1206,    1,    0,   27,    6],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_loader = batch_lyric(encoded_lyrics, sequence_length=5, batch_size=10)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "f, l = train_iter.next()\n",
    "print(f)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # model hyperparameters\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # model layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, n_input, hidden):\n",
    "        batch = n_input.size(0)\n",
    "        \n",
    "        embed = self.embedding(n_input)\n",
    "        l, hidden = self.lstm(embed, hidden)\n",
    "        l = l.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.fc(l)\n",
    "        out = out.view(batch, -1, self.output_size)\n",
    "        out = out[:,-1]\n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        w = next(self.parameters()).data\n",
    "        \n",
    "        if gpu_availability:\n",
    "            hidden = (w.new(self.num_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      w.new(self.num_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (w.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      w.new(self.num_layers, batch_size, self.hidden_dim).zero_())\n",
    "            \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(1731, 300)\n",
      "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=1731, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 300\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "model = Model(vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_back_propagation(model, optimizer, criterion, feat, target, hidden):\n",
    "    if gpu_availability:\n",
    "        model.cuda()\n",
    "        feat, target = feat.cuda(), target.cuda()\n",
    "        \n",
    "    h = tuple([a.data for a in hidden])\n",
    "    model.zero_grad()\n",
    "\n",
    "    out, h = model(feat, h)\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size, optimizer, criterion, epochs, show_every=100):\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print('------------ EPOCH', i+1, '------------')\n",
    "        \n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for batch, (inp, labels) in enumerate(train_loader, 1):\n",
    "            inp = inp.to(torch.int64)\n",
    "            labels = labels.to(torch.int64)\n",
    "            \n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if batch > n_batches:\n",
    "                break\n",
    "            \n",
    "            # forward and back prop\n",
    "            loss, hidden = forward_and_back_propagation(model, optimizer, criterion, inp, labels, hidden)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if batch % show_every == 0:\n",
    "                print('Loss:', np.average(losses))\n",
    "                losses = []\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = batch_lyric(encoded_lyrics, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 300\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ EPOCH 1 ------------\n",
      "Loss: 5.978668212890625\n",
      "Loss: 5.369683704376221\n",
      "Loss: 5.0138031768798825\n",
      "------------ EPOCH 2 ------------\n",
      "Loss: 4.3513053533072785\n",
      "Loss: 4.129555222988128\n",
      "Loss: 4.060740299224854\n",
      "------------ EPOCH 3 ------------\n",
      "Loss: 3.3975519554637303\n",
      "Loss: 3.312002730369568\n",
      "Loss: 3.2575185334682466\n",
      "------------ EPOCH 4 ------------\n",
      "Loss: 2.4020344954784787\n",
      "Loss: 2.5421368396282196\n",
      "Loss: 2.491640272140503\n",
      "------------ EPOCH 5 ------------\n",
      "Loss: 1.7451489907558833\n",
      "Loss: 1.7905638825893402\n",
      "Loss: 1.7745794916152955\n"
     ]
    }
   ],
   "source": [
    "model = Model(vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "if gpu_availability:\n",
    "    model.cuda()\n",
    "    \n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trained_model = train(model, batch_size, opt, criterion, epochs, show_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_lyrics(trained_rnn, start_word, int_to_vocab, punct_token, padding, lyric_length = 100):\n",
    "    trained_rnn.eval()\n",
    "    \n",
    "    # we have only 1 word only in the beginning (start word)\n",
    "    lyric_sequence = np.full((1, sequence_length), padding)\n",
    "    lyric_sequence[-1][-1] = start_word\n",
    "    pred = [int_to_vocab[start_word]]\n",
    "    \n",
    "    for _ in range(lyric_length):\n",
    "        if gpu_availability:\n",
    "            lyric_sequence = torch.LongTensor(lyric_sequence).cuda()\n",
    "        else:\n",
    "            lyric_sequence = torch.LongTensor(lyric_sequence)\n",
    "            \n",
    "        hidden = trained_rnn.init_hidden(lyric_sequence.size(0))\n",
    "        output, _ = trained_rnn(lyric_sequence, hidden)\n",
    "        \n",
    "        candidate_lyrics = F.softmax(output, dim=1).data\n",
    "        if gpu_availability:\n",
    "            candidate_lyrics = candidate_lyrics.cpu()\n",
    "            \n",
    "        top_candidate = 5\n",
    "        candidate_lyrics, chosen_lyrics = candidate_lyrics.topk(top_candidate)\n",
    "        chosen_lyrics = chosen_lyrics.numpy().squeeze()\n",
    "        \n",
    "        candidate_lyrics = candidate_lyrics.numpy().squeeze()\n",
    "        idx = np.random.choice(chosen_lyrics, p=candidate_lyrics/candidate_lyrics.sum())\n",
    "        \n",
    "        lyric = int_to_vocab[idx]\n",
    "        pred.append(lyric)\n",
    "        \n",
    "        lyric_sequence = np.roll(lyric_sequence.cpu(), -1, 1)\n",
    "        lyric_sequence[-1][-1] = idx\n",
    "        \n",
    "    generated_lyrics = ' '.join(pred)\n",
    "    \n",
    "    # convert back punctuation tokens into real punctuations\n",
    "    for punct, token in token_lookup.items():\n",
    "        ending = ' ' if punct in ['\\n', '(', '\"'] else ''\n",
    "        generated_lyrics = generated_lyrics.replace(' ' + token.lower(), punct)\n",
    "    generated_lyrics = generated_lyrics.replace('\\n ', '\\n')\n",
    "    generated_lyrics = generated_lyrics.replace('( ', '(')\n",
    "    \n",
    "    return generated_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간 나의 멈춰 매일 지나가겠죠\n",
      "나의 모든 순간이 아름답고 눈부셔\n",
      "영원토록 뜨겁게 지지 않을게\n",
      "이 모든 계절\n",
      "나의 모든 계절 매일 화려한 이 무대\n",
      "\n",
      "난 지금 이대로가 좋아, ooh ooh\n",
      "창밖의 시선 따윈 필요 없잖아\n",
      "이 순간 내가 원하는 걸 좀 더 꿈꿀래\n",
      "내 안에 나를 더 알고 싶어\n",
      "i' m always curious you(i' m)\n",
      "i' m so curious, i' m so curious\n",
      "\n",
      "wow! my rose\n",
      "\n",
      "i remember\n",
      "네 맘을 흔들어 담은\n",
      "발길을 멈춘 그대\n",
      "i' m your for you\n",
      "(hold me hold me)\n",
      "이 모든 순간이 아름답고 원하는 눈부셔\n",
      "그 날부터 함께 걸어갈게요\n",
      "\n",
      "혼자라면 할 수 없는 이 노래\n",
      "(listen to me)\n",
      "지금 너와 내가 만든 이 무대\n",
      "이 순간 내가 원하는 걸 좀 더 꿈꿀래\n",
      "그 안에 나를 더 알고 싶어\n",
      "(we can feel it)\n",
      "나와 네 손잡아 게 가\n",
      "(hold me hold me feel)\n",
      "\n",
      "now i' m crazy for you, and crazy fallin'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_len = 200\n",
    "start_lyric = '시간'\n",
    "\n",
    "pad_token = PADDING['PADDING']\n",
    "generated_lyrics = generate_lyrics(trained_model, vocab_to_int[start_lyric], int_to_vocab, token_lookup, vocab_to_int[pad_token], lyrics_len)\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
