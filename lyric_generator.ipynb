{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZ*ONE Lyric Generator\n",
    "\n",
    "Welcome to the IZ*ONE Lyric Generator notebook! I will guide you through this notebook on how to preprocess our data and train them with an LSTM network. First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can read our .txt file from the /data directory using the open() function from python. **Don't forget to specify the encoding to 'utf-8' when you are trying to read non-English characters in your lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lyrics text file\n",
    "with open('./data/lyrics.txt', encoding='utf-8') as f:\n",
    "    raw_lyrics = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Statistics\n",
    "\n",
    "It is always a good practice to deep dive inside your data and analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines: 1792\n",
      "Total number of unique words (roughly): 1964\n",
      "Average number of words in a line: 3.763392857142857\n",
      "The least number of words in a line: 0\n",
      "The most number of words in a line: 13\n",
      "\n",
      "Lyric preview:\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "Have you ever seen anything?\n",
      "아름다운 색, 아름다운 색, 아름다운 색\n",
      "Have you ever seen this color?\n",
      "아름다운 색, 아름다운 다운 다운 다운\n",
      "\n",
      "끌리네 그 누구와도 다르게\n",
      "변하고 싶어 나\n",
      "너를 바라보면서 yeah\n",
      "너를 알아가면서 yeah\n",
      "\n",
      "상상이 내 감정을 더 움직여\n",
      "열두 가지 색색깔의 무지개\n",
      "나는 과연 어떤 색일까\n",
      "우리 더 빛나게 해볼까\n",
      "\n",
      "천천히 하나 둘 그리는 하얀 종이 위에\n"
     ]
    }
   ],
   "source": [
    "# data statistics\n",
    "lyrics_per_line = raw_lyrics.split('\\n')\n",
    "word_count_line = [len(line.split()) for line in lyrics_per_line]\n",
    "\n",
    "print('Total number of lines:', len(raw_lyrics.split('\\n')))\n",
    "print('Total number of unique words (roughly):', len({word: None for word in raw_lyrics.split()}))\n",
    "print('Average number of words in a line:', np.average(word_count_line))\n",
    "print('The least number of words in a line:', np.min(word_count_line))\n",
    "print('The most number of words in a line:', np.max(word_count_line))\n",
    "print()\n",
    "\n",
    "view_range = 20\n",
    "print('Lyric preview:')\n",
    "print('\\n'.join(raw_lyrics.split('\\n')[:view_range]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words: ['oh', 'me', '더', '이', 'I', '내꺼', '내', 'da', 'you', 'so']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(raw_lyrics.split())\n",
    "sorted_count = sorted(counter, key=counter.get, reverse=True)\n",
    "print('Top 10 words:', sorted_count[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good thing when analyzing the stats of the data is, in this case, we can see which punctuations appear in the data. When we are working with a sentiment analysis (e.g. predicting whether a review is good or bad), we usually don't really pay attention to them and we can remove them immediately. For lyric generator, I decided to keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def check_punctuations(lyrics):\n",
    "    \"\"\"\n",
    "    Check which punctuations do the lyrics have\n",
    "    \n",
    "    # Arguments\n",
    "        lyrics: input lyrics\n",
    "    \n",
    "    # Output:\n",
    "        (flag, punct_list): boolean flag and list of punctuations found in the lyrics\n",
    "    \"\"\"\n",
    "    \n",
    "    flag = False\n",
    "    punct_list = []\n",
    "    for p in punctuation:\n",
    "        if raw_lyrics.find(p) != -1:\n",
    "            flag = True\n",
    "            punct_list.append(p)\n",
    "\n",
    "    return (flag, punct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, ['!', \"'\", '(', ')', ',', '-', '/', '?'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_punctuations(raw_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "This is the most important part in this project. Before feeding lyrics to the model, we need to transform them in order for the model to understand our goal.\n",
    "\n",
    "<ul>\n",
    "    <li><code>create_lookup_tables</code> function simply turns words into integers and vice versa in descending order</li>\n",
    "    <li><code>create_token_lookup</code> function creates a specific token for each punctuations to distinguish them from normal words </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(lyrics):\n",
    "    \"\"\"\n",
    "    Creates 2 dictionaries which are lookup tables to store:\n",
    "    - word to integer\n",
    "    - integer to word\n",
    "    \n",
    "    # Arguments:\n",
    "        lyrics: List, raw lyrics that split into individual words\n",
    "    \n",
    "    # Output:\n",
    "        Tuple of (vocab_to_int, int_to_vocab)\n",
    "            vocab_to_int: dictionary which maps word to integer\n",
    "            int_to_vocab: dictionary which maps integer to word\n",
    "    \"\"\"\n",
    "    \n",
    "    # creates a word counter by using the Counter class\n",
    "    word_count = Counter(lyrics)\n",
    "    # sorts them by the word frequencies in descending order\n",
    "    sorted_word_count = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    # creates a dictionary that maps words to indexes\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(sorted_word_count)}\n",
    "    # creates a dictionary that maps indexes back to their respective words\n",
    "    int_to_vocab = {idx: word for word, idx in vocab_to_int.items()}\n",
    "    \n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "def create_token_lookup():\n",
    "    \"\"\"\n",
    "    Creates lookup token for punctuations\n",
    "    \n",
    "    # Arguments:\n",
    "        None\n",
    "        \n",
    "    # Output:\n",
    "        String, punctuation token\n",
    "    \"\"\"\n",
    "    \n",
    "    # creates a list of punctuations/special chars\n",
    "    punctuations = ['!', \"'\", '(', ')', ',', '-', '/', '?', '\\n']\n",
    "    # creates a list of punctuations tokens --> THE VALUES HAVE TO BE IN ORDER WITH THE PUNCTUATION LIST!\n",
    "    tokens = ['<EXCLAMATION_MARK>', '<SINGLE_QUOTATION_MARK>', '<LEFT_ROUND_BRACKET>', '<RIGHT_ROUND_BRACKET>',\n",
    "              '<COMMA>', '<HYPHEN>', '<SLASH>', '<QUESTION_MARK>', '<NEW_LINE>']\n",
    "    \n",
    "    punct_token = {}\n",
    "    for p in range(len(punctuations)):\n",
    "        punct_token[punctuations[p]] = tokens[p]\n",
    "        \n",
    "    return punct_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "PADDING = {'PADDING': '<PAD>'} # extra padding token for later when generating lyrics\n",
    "\n",
    "# create token lookup\n",
    "token_lookup = create_token_lookup()\n",
    "# replace punctuations with their respective tokens\n",
    "for symbol, token in token_lookup.items():\n",
    "    raw_lyrics = raw_lyrics.replace(symbol, ' {} '.format(token))\n",
    "\n",
    "tokenized_lyrics = raw_lyrics.lower() # convert lyrics to lower case letters\n",
    "tokenized_lyrics = tokenized_lyrics.split() # then split them into individual words\n",
    "\n",
    "# create both dictionaries vocab_to_int and int_to_vocab\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(tokenized_lyrics + list(PADDING.values()))\n",
    "# save the mapped (encoded) lyrics \n",
    "encoded_lyrics = [vocab_to_int[word] for word in tokenized_lyrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) GPU Training\n",
    "\n",
    "PyTorch has flexibility to train a model with CPU or GPU. Run the code below to check if your local machine is eligible to train with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available! Training on: GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch\n",
    "\n",
    "gpu_availability = torch.cuda.is_available()\n",
    "\n",
    "if gpu_availability:\n",
    "    print('GPU Available! Training on:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU found! Training on CPU...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batching and Sequencing\n",
    "\n",
    "There is one more step before feeding the data to the model, that is data batching and sequencing. In this step, we divide data into several batches within a length of sequence. To makes this easier to understand, let's consider a very simple example:\n",
    "\n",
    "<code>[Big, brown, fox, jumps, over, the, lazy, dog, and, cat]</code>\n",
    "\n",
    "And let's say we want to divide it into 6 different batches with a sequence length of 3:\n",
    "\n",
    "<code>features: [Big, brown, fox] | labels: [jumps]\n",
    "features: [brown, fox, jumps] | labels: [over]\n",
    "features: [fox, jumps, over] | labels: [the]\n",
    "features: [jumps, over, the] | labels: [lazy]\n",
    "features: [over, the, lazy] | labels: [dog]\n",
    "features: [the, lazy, dog] | labels: [and]<br></code>\n",
    "\n",
    "That's how we batch data with a specific sequence length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_lyric(lyrics, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch data within a specific sequence length\n",
    "    \n",
    "    # Arguments\n",
    "        lyrics: List, preprocessed lyrics\n",
    "        sequence length: Integer, the number of sequence length\n",
    "        batch_size: Integer, the number of batches\n",
    "    \n",
    "    # Output\n",
    "        DataLoader, batches of data within a sequence length\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # split lyrics into batches according to the sequence length\n",
    "    for w in range(len(lyrics)):\n",
    "        if w+sequence_length < len(lyrics):\n",
    "            features.append(lyrics[w:w+sequence_length]) # features\n",
    "            labels.append(lyrics[w+sequence_length]) # labels\n",
    "            \n",
    "    # convert them to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    # convert them to tensors and load them by using DataLoader\n",
    "    dataset = TensorDataset(torch.from_numpy(features), torch.from_numpy(labels))\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good practice to test the implementation before actually using it with the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   6,    5,    9,   33,  158],\n",
      "        [1412,  106, 1413,  339,    0],\n",
      "        [   7,  109,  110,  205,   59],\n",
      "        [ 135,   40,    5,   41,  418],\n",
      "        [ 100,   24,  263,    2,   26],\n",
      "        [  54,  350,  435,   50,  486],\n",
      "        [   6,    5,    9,   21,   33],\n",
      "        [   0,   94,  175,  196,  197],\n",
      "        [  23,   27,    1,   27,    1],\n",
      "        [   5,    9,   21,   33,    2]], dtype=torch.int32)\n",
      "tensor([   7,  507,    0,   24,   26, 1206,    1,    0,   27,    6],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_loader = batch_lyric(encoded_lyrics, sequence_length=5, batch_size=10)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "f, l = train_iter.next()\n",
    "print(f)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It's working as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Model\n",
    "\n",
    "Now into the interesting part, building the training model. We will be going to use LSTM (Long Short Term memory) network with word embeddings. We will build our own custom class which an extends from the nn.Module Pytorch class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        \"\"\"\n",
    "        Build an LSTM model\n",
    "        \n",
    "        # Arguments\n",
    "            vocab_size: Integer, how many vocabularies (words) to train\n",
    "            output_size: Integer, output length\n",
    "            embedding_dim: Integer, the number embedding dimensions\n",
    "            hidden_dim: Integer, the number of hidden layer output\n",
    "            num_layers: Integer, the number of hidden layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # model hyperparameters\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # model layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, n_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation\n",
    "        \n",
    "        # Arguments\n",
    "            n_input: Integer, the number of input to the network\n",
    "            hidden: Integer, the number of hidden states\n",
    "        \n",
    "        # Output\n",
    "            (out, hidden): the output and hidden state of the network\n",
    "        \"\"\"\n",
    "        \n",
    "        batch = n_input.size(0)\n",
    "        \n",
    "        # word embeddings\n",
    "        embed = self.embedding(n_input)\n",
    "        # feed to LSTM networks\n",
    "        l, hidden = self.lstm(embed, hidden)\n",
    "        # don't forget to call .contiguous() and reshape the tensor\n",
    "        l = l.contiguous().view(-1, self.hidden_dim)\n",
    "        # fully connected layer\n",
    "        out = self.fc(l)\n",
    "        # reshape the tensor with the number of batches in the front\n",
    "        out = out.view(batch, -1, self.output_size)\n",
    "        # take the only the last output\n",
    "        out = out[:,-1]\n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize hidden state\n",
    "        \n",
    "        # Arguments\n",
    "            batch_size: Integer, number of batches\n",
    "        \n",
    "        # Output\n",
    "            hidden: hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        w = next(self.parameters()).data\n",
    "        \n",
    "        if gpu_availability:\n",
    "            hidden = (w.new(self.num_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      w.new(self.num_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (w.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      w.new(self.num_layers, batch_size, self.hidden_dim).zero_())\n",
    "            \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(1731, 300)\n",
      "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=1731, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize layer hyperparameters\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 300\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "# initialize the model\n",
    "model = Model(vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_back_propagation(model, optimizer, criterion, feat, target, hidden):\n",
    "    \"\"\"\n",
    "    Execute forward and back propagation\n",
    "    \n",
    "    # Arguments:\n",
    "        model: Model, an RNN model\n",
    "        optimizer: torch.optim, model optimizer\n",
    "        criterion: loss criterion (cross entropy)\n",
    "        feat: Tensor, features\n",
    "        target: Tensor, labels\n",
    "        hidden: hidden state\n",
    "    \n",
    "    # Output:\n",
    "        (loss, h): Loss and hidden state\n",
    "    \"\"\"\n",
    "    \n",
    "    # move features and labels to GPU if available\n",
    "    if gpu_availability:\n",
    "        model.cuda()\n",
    "        feat, target = feat.cuda(), target.cuda()\n",
    "    # hidden states\n",
    "    h = tuple([a.data for a in hidden])\n",
    "    # clear out gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # forward propagation\n",
    "    out, h = model(feat, h)\n",
    "    # calculate loss\n",
    "    loss = criterion(out, target)\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 5) # clip any large gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size, optimizer, criterion, epochs, show_every=100):\n",
    "    \"\"\"\n",
    "    Train an RNN model\n",
    "    \n",
    "    # Arguments:\n",
    "        model: Model, an RNN model\n",
    "        batch_size: Integer, number of batches\n",
    "        optimizer: torch.optim, model optimizer\n",
    "        criterion: loss criterion (cross entropy)\n",
    "        epochs: Integer, the number of training iterations\n",
    "        show_every: Integer, show the training progress every n iteration\n",
    "        \n",
    "    # Output:\n",
    "        model: the trained RNN model\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    model.train() # set the model to training mode\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print('------------ EPOCH', i+1, '------------')\n",
    "        \n",
    "        hidden = model.init_hidden(batch_size) # initialize hidden states\n",
    "        \n",
    "        for batch, (inp, labels) in enumerate(train_loader, 1):\n",
    "            # converts tensors to int64. I noticed this is only for windows platform only\n",
    "            # don't need to add this if you are not working on windows\n",
    "            inp = inp.to(torch.int64)\n",
    "            labels = labels.to(torch.int64)\n",
    "            \n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if batch > n_batches:\n",
    "                break\n",
    "            \n",
    "            # forward and back prop\n",
    "            loss, hidden = forward_and_back_propagation(model, optimizer, criterion, inp, labels, hidden)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if batch % show_every == 0:\n",
    "                print('Loss:', np.average(losses))\n",
    "                losses = []\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Alright, now we are ready to train the model. Remember before feeding the data to the model, we need to divide them into batches and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch sequence the lyrics\n",
    "sequence_length = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = batch_lyric(encoded_lyrics, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Hyperparameters\n",
    "\n",
    "Feel free to try different numbers and combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "# model hyperparameters\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 300\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ EPOCH 1 ------------\n",
      "Loss: 5.978668212890625\n",
      "Loss: 5.369683704376221\n",
      "Loss: 5.0138031768798825\n",
      "------------ EPOCH 2 ------------\n",
      "Loss: 4.3513053533072785\n",
      "Loss: 4.129555222988128\n",
      "Loss: 4.060740299224854\n",
      "------------ EPOCH 3 ------------\n",
      "Loss: 3.3975519554637303\n",
      "Loss: 3.312002730369568\n",
      "Loss: 3.2575185334682466\n",
      "------------ EPOCH 4 ------------\n",
      "Loss: 2.4020344954784787\n",
      "Loss: 2.5421368396282196\n",
      "Loss: 2.491640272140503\n",
      "------------ EPOCH 5 ------------\n",
      "Loss: 1.7451489907558833\n",
      "Loss: 1.7905638825893402\n",
      "Loss: 1.7745794916152955\n"
     ]
    }
   ],
   "source": [
    "# initialize model and move it to GPU if available\n",
    "model = Model(vocab_size, output_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "if gpu_availability:\n",
    "    model.cuda()\n",
    "\n",
    "# initialize model optimizer and loss function\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train the model\n",
    "trained_model = train(model, batch_size, opt, criterion, epochs, show_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! I got around 1.77 loss after 5 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generating New Lyrics\n",
    "\n",
    "Let's test our model to generate some new lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_lyrics(trained_rnn, start_word, int_to_vocab, punct_token, padding, lyric_length = 100):\n",
    "    \"\"\"\n",
    "    Generate lyrics from the trained RNN model\n",
    "    \n",
    "    # Arguments:\n",
    "        trained_rnn: the trained RNN model\n",
    "        start_word: String, input word to start generating lyrics\n",
    "        int_to_vocab: A dictionary containing word to index\n",
    "        punct_token: punctuation token\n",
    "        padding: padding token (<PAD>)\n",
    "        lyric_length: Integer, output length of the generated lyrics\n",
    "        \n",
    "    # Output:\n",
    "        generated_lyrics: The final output of generated lyrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # set model to evaluation mode\n",
    "    trained_rnn.eval()\n",
    "    \n",
    "    # we have only 1 word only in the beginning (start word)\n",
    "    lyric_sequence = np.full((1, sequence_length), padding)\n",
    "    lyric_sequence[-1][-1] = start_word\n",
    "    pred = [int_to_vocab[start_word]]\n",
    "    \n",
    "    for _ in range(lyric_length):\n",
    "        # move tensors to GPU if available\n",
    "        if gpu_availability:\n",
    "            lyric_sequence = torch.LongTensor(lyric_sequence).cuda()\n",
    "        else:\n",
    "            lyric_sequence = torch.LongTensor(lyric_sequence)\n",
    "        \n",
    "        # forward propagation\n",
    "        hidden = trained_rnn.init_hidden(lyric_sequence.size(0))\n",
    "        output, _ = trained_rnn(lyric_sequence, hidden)\n",
    "        \n",
    "        # extract the softmax output\n",
    "        candidate_lyrics = F.softmax(output, dim=1).data\n",
    "        # move it to cpu\n",
    "        if gpu_availability:\n",
    "            candidate_lyrics = candidate_lyrics.cpu()\n",
    "        \n",
    "        # choose top 5 words with the highest probabilities from the softmax output\n",
    "        top_candidate = 5\n",
    "        candidate_lyrics, chosen_lyrics = candidate_lyrics.topk(top_candidate)\n",
    "        # convert tensor to numpy\n",
    "        chosen_lyrics = chosen_lyrics.numpy().squeeze()\n",
    "        candidate_lyrics = candidate_lyrics.numpy().squeeze()\n",
    "        # random factor\n",
    "        idx = np.random.choice(chosen_lyrics, p=candidate_lyrics/candidate_lyrics.sum())\n",
    "        \n",
    "        lyric = int_to_vocab[idx] # convert indexes back to words\n",
    "        pred.append(lyric)\n",
    "        \n",
    "        # move the start word 'pointer' to the next word (generated word from the model) and repeat\n",
    "        lyric_sequence = np.roll(lyric_sequence.cpu(), -1, 1)\n",
    "        lyric_sequence[-1][-1] = idx\n",
    "        \n",
    "    generated_lyrics = ' '.join(pred)\n",
    "    \n",
    "    # convert back punctuation tokens into real punctuations\n",
    "    for punct, token in token_lookup.items():\n",
    "        ending = ' ' if punct in ['\\n', '(', '\"'] else ''\n",
    "        generated_lyrics = generated_lyrics.replace(' ' + token.lower(), punct)\n",
    "    generated_lyrics = generated_lyrics.replace('\\n ', '\\n')\n",
    "    generated_lyrics = generated_lyrics.replace('( ', '(')\n",
    "    \n",
    "    return generated_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간 나의 멈춰 매일 지나가겠죠\n",
      "나의 모든 순간이 아름답고 눈부셔\n",
      "영원토록 뜨겁게 지지 않을게\n",
      "이 모든 계절\n",
      "나의 모든 계절 매일 화려한 이 무대\n",
      "\n",
      "난 지금 이대로가 좋아, ooh ooh\n",
      "창밖의 시선 따윈 필요 없잖아\n",
      "이 순간 내가 원하는 걸 좀 더 꿈꿀래\n",
      "내 안에 나를 더 알고 싶어\n",
      "i' m always curious you(i' m)\n",
      "i' m so curious, i' m so curious\n",
      "\n",
      "wow! my rose\n",
      "\n",
      "i remember\n",
      "네 맘을 흔들어 담은\n",
      "발길을 멈춘 그대\n",
      "i' m your for you\n",
      "(hold me hold me)\n",
      "이 모든 순간이 아름답고 원하는 눈부셔\n",
      "그 날부터 함께 걸어갈게요\n",
      "\n",
      "혼자라면 할 수 없는 이 노래\n",
      "(listen to me)\n",
      "지금 너와 내가 만든 이 무대\n",
      "이 순간 내가 원하는 걸 좀 더 꿈꿀래\n",
      "그 안에 나를 더 알고 싶어\n",
      "(we can feel it)\n",
      "나와 네 손잡아 게 가\n",
      "(hold me hold me feel)\n",
      "\n",
      "now i' m crazy for you, and crazy fallin'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_len = 200\n",
    "start_lyric = '시간'\n",
    "\n",
    "pad_token = PADDING['PADDING']\n",
    "generated_lyrics = generate_lyrics(trained_model, vocab_to_int[start_lyric], int_to_vocab, token_lookup, vocab_to_int[pad_token], lyrics_len)\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
